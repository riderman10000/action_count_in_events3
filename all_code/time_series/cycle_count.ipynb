{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd32bbde",
   "metadata": {},
   "source": [
    "# Find a monotonous jumping point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84a6c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through Mann-Kendall as a monotonous judgment standard\n",
    "# DATA is the time sequence server\n",
    "def get_index_of_bottom_and_top_by_mk(data):\n",
    "    win_size=10\n",
    "    step=5\n",
    "    first = np.inf\n",
    "    second = -np.inf\n",
    "    flag = True\n",
    "    final_win_change = None\n",
    "    while(second < first):\n",
    "        # Record the total number of pane divided\n",
    "        win_sum = int(1 + (data.shape[0]-win_size)/step if data.shape[0] > win_size else 0)\n",
    "        # Each pane starting index\n",
    "        win_start_index = np.arange(0,win_sum*step,step=step)\n",
    "        # Mutation pane index [Later processing as an intermediate index in the middle pane]\n",
    "        win_change = np.array([])\n",
    "        # Current window trend [Increasing, Decreasing, No Trend]\n",
    "        win_trend = np.array([])\n",
    "\n",
    "        # Traverson all pane\n",
    "        for i in range(win_sum):\n",
    "            # Pane data\n",
    "            win_data = data[win_start_index[i]:win_start_index[i]+win_size]\n",
    "            # Add the current window trend\n",
    "            win_trend = np.append(win_trend,mk.original_test(win_data)[0])  \n",
    "\n",
    "        # Traversing the trend of each pane\n",
    "        for i in range(1,win_trend.shape[0]):\n",
    "            # The previous one is not increasing, and the current is increasing, indicating that this is a mutation point\n",
    "            if win_trend[i] == 'increasing' and win_trend[i-1]!='increasing':\n",
    "                win_change = np.append(win_change,win_start_index[i-1])\n",
    "            elif win_trend[i] == 'decreasing' and win_trend[i-1]!='decreasing':\n",
    "                win_change = np.append(win_change,win_start_index[i-1])\n",
    "\n",
    "        # The window takes the intermediate value as the segmentation line\n",
    "        win_change = win_change + win_size/2\n",
    "        win_change = win_change.astype(np.int32)\n",
    "        # Start and end the division line\n",
    "        win_change = np.insert(win_change,0,0)\n",
    "        # -1 Prevent cross -border\n",
    "        win_change = np.append(win_change,data.shape[0]-1)\n",
    "        # The variance of currently dividing the pane\n",
    "        variance = np.var(np.diff(win_change))\n",
    "        if flag:\n",
    "            first = variance\n",
    "        else:\n",
    "            second = variance\n",
    "        # It shows that the variance of the square difference at this time is greater than the difference in the previous cutting method. Select the previous cutting method as the final method\n",
    "        if second >= first:\n",
    "            break\n",
    "        flag = not flag\n",
    "        win_size = win_size + 5\n",
    "        final_win_change = win_change\n",
    "    \n",
    "    # The index is the starting label of the rising edge to 1 to 1\n",
    "    top_win = np.zeros(final_win_change.shape[0])\n",
    "    if data[final_win_change[0]] <= data[final_win_change[1]]:\n",
    "        top_win[0] = 1\n",
    "    for i in range(1,final_win_change.shape[0]):\n",
    "        if data[final_win_change[i-1]] >= data[final_win_change[i]]:\n",
    "            top_win[i] = 1 \n",
    "    return final_win_change,top_win,win_size,step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c1886",
   "metadata": {},
   "source": [
    "# Cycle count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "913a4a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(result):\n",
    "    count = 1\n",
    "    for i in range(result.shape[0]):\n",
    "        # 0 without processing\n",
    "        if i == 0 or result[i] == 0 or result[i-1]==0:\n",
    "            continue\n",
    "        # The two errors are small, which is the same action\n",
    "        if result[i]-result[i-1] <= 2:\n",
    "            count = count + 1\n",
    "        # 0\n",
    "        else:\n",
    "            return count\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93baa241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return time sequence rise/decrease along the average value of the price after the mutual comparison\n",
    "def get_dtw_mean_cost(win_change,top_win,data):\n",
    "    win_change_length = win_change.shape[0]\n",
    "    # Rising along the number\n",
    "    top_count = np.count_nonzero(top_win==1)\n",
    "    # Drop along the number\n",
    "    bottom_count = top_win.shape[0] - top_count\n",
    "    # Storage rising along dtw comparison results\n",
    "    avg_cost_by_dtw_top = np.zeros(shape=(top_count,top_count))\n",
    "    avg_cost_by_dtw_bottom = np.zeros(shape=(bottom_count,bottom_count))\n",
    "    # Rising/down index along the line\n",
    "    k_top = 0\n",
    "    k_bottom = 0\n",
    "    # Column index\n",
    "    g_top = 0\n",
    "    g_bottom = 0\n",
    "    # Guaranteed not to cross the border, bubbling comparison\n",
    "    for i in range(0,win_change_length-1):\n",
    "        # Avoid repeated comparisons in the same paragraph\n",
    "        if top_win[i] == top_win[i+1]:\n",
    "            continue\n",
    "        # Explain that I point to the beginning of the rising edge\n",
    "        if top_win[i] == 1:\n",
    "            g_top = k_top + 1\n",
    "        else:\n",
    "            g_bottom = k_bottom + 1\n",
    "        for j in range(i+1,win_change_length-1):\n",
    "            if top_win[j]==top_win[j+1]:\n",
    "                continue\n",
    "            # You need to let J point to the latter of i rising edge\n",
    "            if top_win[i] == 1 and top_win[j] == 1:\n",
    "                # Get the matching price of two time sequences\n",
    "                cost, _ = fastdtw(data[win_change[i]:win_change[i+1]], data[win_change[j]:win_change[j+1]])\n",
    "                # Stay in the comparison of the rising along the comparison\n",
    "                num = data[win_change[j]:win_change[j+1]].shape[0] + data[win_change[i]:win_change[i+1]].shape[0]\n",
    "                avg_cost_by_dtw_top[k_top][g_top] = cost/num\n",
    "                avg_cost_by_dtw_top[g_top][k_top] = cost/num\n",
    "                g_top = g_top + 1\n",
    "            elif top_win[i] == 0 and top_win[j] == 0:\n",
    "                # Get the matching price of two time sequences\n",
    "                cost, _ = fastdtw(data[win_change[i]:win_change[i+1]], data[win_change[j]:win_change[j+1]])\n",
    "                # Stay in the comparison of the rising along the comparison\n",
    "                num = data[win_change[j]:win_change[j+1]].shape[0] + data[win_change[i]:win_change[i+1]].shape[0]\n",
    "                avg_cost_by_dtw_bottom[k_bottom][g_bottom] = cost/num\n",
    "                avg_cost_by_dtw_bottom[g_bottom][k_bottom] = cost/num\n",
    "                g_top = g_top + 1\n",
    "            \n",
    "        if top_win[i] == 1:\n",
    "            k_top = k_top + 1\n",
    "        else:\n",
    "            k_bottom = k_bottom + 1\n",
    "    # Delete the full 0 line and the last 0 delete\n",
    "    avg_cost_by_dtw_top = avg_cost_by_dtw_top[:-1,:-1]\n",
    "    avg_cost_by_dtw_bottom = avg_cost_by_dtw_bottom[:-1,:-1]\n",
    "    # Replace your own comparison price to the average value of other numbers\n",
    "    for arr in avg_cost_by_dtw_top:\n",
    "        if arr.shape[0] != 1:\n",
    "            temp = np.sum(arr)/(arr.shape[0]-1)\n",
    "            arr[arr==0] = temp\n",
    "    for arr in avg_cost_by_dtw_bottom:\n",
    "        if arr.shape[0] != 1:\n",
    "            temp = np.sum(arr)/(arr.shape[0]-1)\n",
    "            arr[arr==0] = temp\n",
    "    result_top = np.array([])\n",
    "    result_bottom = np.array([])\n",
    "    if avg_cost_by_dtw_top.shape[0] != 0:\n",
    "        result_top = np.sort(np.mean(avg_cost_by_dtw_top,axis=1))\n",
    "    if avg_cost_by_dtw_bottom.shape[0] != 0:\n",
    "        result_bottom = np.sort(np.mean(avg_cost_by_dtw_bottom,axis=1))\n",
    "    # Get the rising edge count\n",
    "    count_top = get_count(result_top)\n",
    "    # Drop counting count\n",
    "    count_bottom = get_count(result_bottom)\n",
    "    # Back to the upper and lower edge counts larger\n",
    "    return count_top if count_top > count_bottom else count_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b90199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_by_cost(file_name,class_num=-1,nature_flag=True):\n",
    "    file_path = None\n",
    "    if nature_flag:\n",
    "        file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/smooth_by_pca/compress_by_mean/{file_name}'\n",
    "    else:\n",
    "        # Artificial synthesis data\n",
    "        file_path = f'../../event_csv/compress_event_manhattan/articicial/smooth_by_pca/compress_by_mean/{file_name}'\n",
    "    # Data after PCA\n",
    "    pca_data = pd.read_csv(file_path)['value']\n",
    "    win_change,top_win,win_size,step = get_index_of_bottom_and_top_by_mk(pca_data)\n",
    "    return get_dtw_mean_cost(win_change,top_win,pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all action cycle prediction information\n",
    "def get_all_count(file_names,nature_flag=True):\n",
    "    # Storage predictive value\n",
    "    pred_count = np.array([])\n",
    "    if nature_flag:\n",
    "        for i in range(2,8):\n",
    "            for name in file_names:\n",
    "                if i==3:\n",
    "                    continue\n",
    "                count = get_count_by_cost(f'{name}',i)\n",
    "                pred_count = np.append(pred_count,count)\n",
    "                print(f'The file name is {name} middle class_num={i} the number of repetitions of the action is:{count}')\n",
    "            print('-----------------')\n",
    "    else:\n",
    "        # Artificial synthesis data\n",
    "        for name in file_names:\n",
    "            count = get_count_by_cost(name,nature_flag=False)\n",
    "            pred_count = np.append(pred_count,count)\n",
    "            print(f'The file name is {name} the number of repetitions of the action is:{count}')\n",
    "    return pred_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7a7df8",
   "metadata": {},
   "source": [
    "# Results criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109bdfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error, an average absolute error\n",
    "def MAE(pred_count,real_count):\n",
    "    return np.mean(np.abs(real_count - pred_count)/real_count)\n",
    "# OffBy-One (OBO) count error.\n",
    "def OBO(pred_count,real_count):\n",
    "    # Predictive value and real value error\n",
    "    temp = np.abs(real_count-pred_count)\n",
    "    # The proportion of the prediction value of the error is less than the same\n",
    "    return temp[temp<=1].shape[0]/temp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7384350",
   "metadata": {},
   "source": [
    "# PCA main component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2159bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_method(data):\n",
    "    # Get the NDARAY form of DataFrame\n",
    "    data = data.values\n",
    "    # One -dimensional\n",
    "    pca = PCA(n_components=1)\n",
    "    # Apply PCA to data\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    pca_data = np.reshape(pca_data,-1)\n",
    "    # HP filter\n",
    "    _, smooth = sm.tsa.filters.hpfilter(pca_data)\n",
    "    return smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b4f055",
   "metadata": {},
   "source": [
    "# Index calculations under different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50db79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overall error of different movements under the same light\n",
    "def same_illumination_diff_action(file_names,pred_count):\n",
    "    start = 0\n",
    "    for name in file_names:\n",
    "        print(f'Light conditions are{name[7:-4]}MAE=',MAE(pred_count[start::5],nature_real_count[start::5]))\n",
    "        print(f'The light condition in the repnet is{name[7:-4]}MAE=',MAE(repnet_nature_pred_count[start::5],nature_real_count[start::5]))\n",
    "        print(f'Light conditions are{name[7:-4]}OBO=',OBO(pred_count[start::5],nature_real_count[start::5]))\n",
    "        print(f'The light condition in the repnet is{name[7:-4]}OBO=',OBO(repnet_nature_pred_count[start::5],nature_real_count[start::5]))\n",
    "        start = start + 1\n",
    "        print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9da703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the overall error of the same action under different light\n",
    "def diff_illumination_same_action(pred_count):\n",
    "    start = 0\n",
    "    for i in range(2,8):\n",
    "        if i == 3:\n",
    "            continue\n",
    "        print(f'class={i}MAE of action=',MAE(pred_count[start:start+5],nature_real_count[start:start+5]))\n",
    "        print(f'repnet middleclass={i}MAE of action=',MAE(repnet_nature_pred_count[start:start+5],nature_real_count[start:start+5]))\n",
    "        print(f'class={i}Action OBO=',OBO(pred_count[start:start+5],nature_real_count[start:start+5]))\n",
    "        print(f'repnet class={i}Action OBO=',OBO(repnet_nature_pred_count[start:start+5],nature_real_count[start:start+5]))\n",
    "        \n",
    "        start = start + 5\n",
    "        print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial synthesis data same，mid，back\n",
    "def print_artificial_MAE_OBO(file_names,real_count,our_count,rep_count):\n",
    "    i = 0\n",
    "    real_d2 = np.array([])\n",
    "    real_d3 = np.array([])\n",
    "    real_d4 = np.array([])\n",
    "    our_d2 = np.array([])\n",
    "    our_d3 = np.array([])\n",
    "    our_d4 = np.array([])\n",
    "    rep_d2 = np.array([])\n",
    "    rep_d3 = np.array([])\n",
    "    rep_d4 = np.array([])\n",
    "    for name in file_names:\n",
    "        count = name.count('_')\n",
    "        # Explanation is the statistical result of the same action(D2)\n",
    "        if count == 0:\n",
    "            real_d2 = np.append(real_d2,real_count[i])\n",
    "            our_d2 = np.append(our_d2,our_count[i])\n",
    "            rep_d2 = np.append(rep_d2,rep_count[i])\n",
    "        # Explanation is the movement of front and back stitching(D3)\n",
    "        elif count == 1:\n",
    "            real_d3 = np.append(real_d3,real_count[i])\n",
    "            our_d3 = np.append(our_d3,our_count[i])\n",
    "            rep_d3 = np.append(rep_d3,rep_count[i])\n",
    "        # Explanation is the action of stitching in the middle of the clip(D4)\n",
    "        elif count == 2:\n",
    "            real_d4 = np.append(real_d4,real_count[i])\n",
    "            our_d4 = np.append(our_d4,our_count[i])\n",
    "            rep_d4 = np.append(rep_d4,rep_count[i])\n",
    "        i = i + 1\n",
    "    print('MAE corresponding to D2 dataset repnet:',MAE(rep_d2,real_d2))\n",
    "    print('OBO corresponding to the D2 dataset repnet:',OBO(rep_d2,real_d2))\n",
    "    print('MAE corresponding to the D2 data set OUR:',MAE(our_d2,real_d2))\n",
    "    print('OBO corresponding to the D2 data set OUR:',OBO(our_d2,real_d2))\n",
    "    print('---------------------------------------------')\n",
    "    print('MAE corresponding to the D3 dataset repnet:',MAE(rep_d3,real_d3))\n",
    "    print('OBO corresponding to the D3 dataset repnet:',OBO(rep_d3,real_d3))\n",
    "    print('MAE corresponding to the D3 data set OUR:',MAE(our_d3,real_d3))\n",
    "    print('OBO corresponding to the D3 data set OUR:',OBO(our_d3,real_d3))\n",
    "    print('---------------------------------------------')\n",
    "    print('MAE corresponding to D4 dataset repnet:',MAE(rep_d4,real_d4))\n",
    "    print('OBO corresponding to the D4 dataset repnet:',OBO(rep_d4,real_d4))\n",
    "    print('MAE corresponding to the D4 data set OUR:',MAE(our_d4,real_d4))\n",
    "    print('OBO corresponding to the D4 data set OUR:',OBO(our_d4,real_d4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.844px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
