{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.font_manager import FontProperties\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy.spatial.distance as dist \n",
    "from scipy.stats import kurtosis, skew \n",
    "from pylab import mpl \n",
    "import pymannkendall as mk \n",
    "import statsmodels.api as sm \n",
    "from fastdtw import fastdtw \n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "# set font \n",
    "mpl.rcParams['font.sans-serif'] = [\"SimHei\"]\n",
    "# solve the problem of negative sign display \n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "# set the width of the coordinate axis \n",
    "plt.rcParams['axes.linewidth'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "# get natural data file name \n",
    "file_names = os.listdir(\"../../event_csv/split_data/class2/\")\n",
    "# get artificial data file name \n",
    "files = os.listdir('../../event_csv/split_data/artificial/')\n",
    "\n",
    "# true data of the original data \n",
    "nature_real_count = np.load('../npy_file/nature_data_real_count.npy')\n",
    "# artificial data real count tag \n",
    "artificial_real_count = np.load('../npy_file/artificial_data_real_count.npy')\n",
    "\n",
    "# repnet network's predicitve label on original data \n",
    "repnet_nature_pred_count = np.load('../npy_file/repnet_nature_data_real_count.npy')\n",
    "# repnet network's prediction label on artificial syntheic data \n",
    "repnet_artificial_pred_count = np.load('../npy_file/repnet_artificial_data_real_count.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "# os.getcwd()\n",
    "sys.path.append('../') # going a step back so the importer can find the following module\n",
    "from time_series_scripts import artificial_data_compose "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 - Artificial synthesis data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - 1 - Synthetic synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A action synthesis repeat number \n",
    "# a_repeat_times = [3, 7, 12, 17]\n",
    "# for i in a_repeat_times:\n",
    "#     artificial_data_compose.get_same(file_name='a', repeat_times=i)\n",
    "\n",
    "# # B action synthesis repeat number \n",
    "# b_repeat_times = [3, 7, 13, 18]\n",
    "# for i in b_repeat_times:\n",
    "#     artificial_data_compose.get_same(file_name='b', repeat_times=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - 2 - front and rear action stitching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A action stitching 3 times and then stitching B action 7 times \n",
    "# artificial_data_compose.get_front_or_tail(repeat_times_A=3, repeat_times_B=7)\n",
    "\n",
    "# A action stitching 3 times and then stitching B action 7 times \n",
    "# artificial_data_compose.get_front_or_tail(repeat_times_A=3, repeat_times_B=13)\n",
    "\n",
    "# A action stitching 3 times and then stitching B action 7 times \n",
    "# artificial_data_compose.get_front_or_tail(repeat_times_A=3, repeat_times_B=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - 3 - before the middle and rear action stitching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # on both sides are A action, the middle is B action\n",
    "# artificial_data_compose.get_mid(repeat_times_A=3, repeat_times_B=13, flag=True)\n",
    "# artificial_data_compose.get_mid(repeat_times_A=3, repeat_times_B=18, flag=True)\n",
    "# artificial_data_compose.get_mid(repeat_times_A=1, repeat_times_B=7, flag=True)\n",
    "\n",
    "# Flag is false on behalf of A action to be sandwiched in the middle\n",
    "# artificial_data_compose.get_mid(repeat_times_A=3, repeat_times_B=13, flag=False)\n",
    "# artificial_data_compose.get_mid(repeat_times_A=3, repeat_times_B=18, flag=False)\n",
    "# artificial_data_compose.get_mid(repeat_times_A=1, repeat_times_B=7, flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - 4 - Artificial data synthesis video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store with 2,000 incident points as a picture \n",
    "# from time_series_scripts import csv_to_video\n",
    "# for name in files:\n",
    "#     csv_to_video.event_to_pic(name[:-4])\n",
    "# # switch the picture into a video with a frame rate of 15\n",
    "# for name in files:\n",
    "    # csv_to_video.pic_to_video(f'../../video/artificial/{name[:-4]}/',f'../../video/artificial_video/{name[:-4]}.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Event data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  d1,d2 = compute_distance(row[1],row[2],df['x'][index+1],df['y'][index+1])\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  baseline_x = row[1]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:56: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  baseline_y = row[2]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:68: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x_dis, y_dis = compute_distance(baseline_x, baseline_y, row[1], row[2])\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:73: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_x = temp_x + row[1]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_y = temp_y + row[2]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:88: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  baseline_x = row[1]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  baseline_y = row[2]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_x = row[1]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:91: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_y = row[2]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x_dis,y_dis = compute_distance(row[1],row[2],next_event[1],next_event[2])\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  d1,d2 = compute_distance(row[1],row[2],df['x'][index+1],df['y'][index+1])\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  baseline_x = row[1]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:56: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  baseline_y = row[2]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:68: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x_dis, y_dis = compute_distance(baseline_x, baseline_y, row[1], row[2])\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:73: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_x = temp_x + row[1]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:74: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_y = temp_y + row[2]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:88: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  baseline_x = row[1]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  baseline_y = row[2]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:90: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_x = row[1]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:91: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  temp_y = row[2]\n",
      "/home/rlwagun/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  x_dis,y_dis = compute_distance(row[1],row[2],next_event[1],next_event[2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m file_names:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mdata_compress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistance_mean_meanline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:155\u001b[0m, in \u001b[0;36mdistance_mean_meanline\u001b[0;34m(file_name, class_num, delta, count, mean_count, nature_flag)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistance_mean_meanline\u001b[39m(file_name,class_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,mean_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,nature_flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# Manhattan distance compression\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     \u001b[43mcompress_by_Manhattan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclass_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcount_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnature_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnature_flag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# PCA + HP filter\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     dimensionality_reduction_PCA(file_name,class_num,nature_flag\u001b[38;5;241m=\u001b[39mnature_flag)\n",
      "File \u001b[0;32m~/Files/action_count_in_events3/all_code/time_series/../time_series_scripts/data_compress.py:68\u001b[0m, in \u001b[0;36mcompress_by_Manhattan\u001b[0;34m(file_name, class_num, delta, count_margin, nature_flag)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# at the distance from manhattan, gather at a point, take the average  value \u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m x_dis, y_dis \u001b[38;5;241m=\u001b[39m compute_distance(baseline_x, baseline_y, \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, row[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# focus on up to count_margin a point \u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_dis \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m delta \u001b[38;5;129;01mand\u001b[39;00m y_dis \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m delta \u001b[38;5;129;01mand\u001b[39;00m count \u001b[38;5;241m<\u001b[39m count_margin:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# denominator of average \u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyenv/lib/python3.11/site-packages/pandas/core/series.py:1109\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     key \u001b[38;5;241m=\u001b[39m unpack_1tuple(key)\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_should_fallback_to_positional:\n\u001b[0;32m-> 1109\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;66;03m# GH#50617\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.__getitem__ treating keys as positions is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn a future version, integer keys will always be treated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas labels (consistent with DataFrame behavior). To access \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma value by position, use `ser.iloc[pos]`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1115\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1116\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1117\u001b[0m     )\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time_series_scripts import data_compress\n",
    "## 1 - 1 - natural data processing\n",
    "for i in range(2, 8):\n",
    "    if i == 3:\n",
    "        continue \n",
    "    for name in file_names:\n",
    "        data_compress.distance_mean_meanline(name, class_num=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual data processing \n",
    "# for name in files:\n",
    "#     data_compress.distance_mean_meanline(name, class_num=-1, nature_flag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Get Statistical counting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fastdtw in module fastdtw.fastdtw:\n",
      "\n",
      "fastdtw(x, y, radius=1, dist=None)\n",
      "    return the approximate distance between 2 time series with O(N)\n",
      "    time and memory complexity\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like\n",
      "        input array 1\n",
      "    y : array_like\n",
      "        input array 2\n",
      "    radius : int\n",
      "        size of neighborhood when expanding the path. A higher value will\n",
      "        increase the accuracy of the calculation but also increase time\n",
      "        and memory consumption. A radius equal to the size of x and y will\n",
      "        yield an exact dynamic time warping calculation.\n",
      "    dist : function or int\n",
      "        The method for calculating the distance between x[i] and y[j]. If\n",
      "        dist is an int of value p > 0, then the p-norm will be used. If\n",
      "        dist is a function then dist(x[i], y[j]) will be used. If dist is\n",
      "        None then abs(x[i] - y[j]) will be used.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    distance : float\n",
      "        the approximate distance between the 2 time series\n",
      "    path : list\n",
      "        list of indexes for the inputs x and y\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> import fastdtw\n",
      "    >>> x = np.array([1, 2, 3, 4, 5], dtype='float')\n",
      "    >>> y = np.array([2, 3, 4], dtype='float')\n",
      "    >>> fastdtw.fastdtw(x, y)\n",
      "    (2.0, [(0, 0), (1, 0), (2, 1), (3, 2), (4, 2)])\n",
      "\n",
      "The file name is user02_lab.csv middle class_num=2 the number of repetitions of the action is:13\n",
      "The file name is user02_natural.csv middle class_num=2 the number of repetitions of the action is:12\n",
      "The file name is user02_fluorescent.csv middle class_num=2 the number of repetitions of the action is:15\n",
      "The file name is user02_led.csv middle class_num=2 the number of repetitions of the action is:12\n",
      "The file name is user02_fluorescent_led.csv middle class_num=2 the number of repetitions of the action is:13\n",
      "-----------------\n",
      "-----------------\n",
      "The file name is user02_lab.csv middle class_num=4 the number of repetitions of the action is:10\n",
      "The file name is user02_natural.csv middle class_num=4 the number of repetitions of the action is:11\n",
      "The file name is user02_fluorescent.csv middle class_num=4 the number of repetitions of the action is:9\n",
      "The file name is user02_led.csv middle class_num=4 the number of repetitions of the action is:8\n",
      "The file name is user02_fluorescent_led.csv middle class_num=4 the number of repetitions of the action is:9\n",
      "-----------------\n",
      "The file name is user02_lab.csv middle class_num=5 the number of repetitions of the action is:9\n",
      "The file name is user02_natural.csv middle class_num=5 the number of repetitions of the action is:9\n",
      "The file name is user02_fluorescent.csv middle class_num=5 the number of repetitions of the action is:10\n",
      "The file name is user02_led.csv middle class_num=5 the number of repetitions of the action is:8\n",
      "The file name is user02_fluorescent_led.csv middle class_num=5 the number of repetitions of the action is:7\n",
      "-----------------\n",
      "The file name is user02_lab.csv middle class_num=6 the number of repetitions of the action is:10\n",
      "The file name is user02_natural.csv middle class_num=6 the number of repetitions of the action is:9\n",
      "The file name is user02_fluorescent.csv middle class_num=6 the number of repetitions of the action is:10\n",
      "The file name is user02_led.csv middle class_num=6 the number of repetitions of the action is:8\n",
      "The file name is user02_fluorescent_led.csv middle class_num=6 the number of repetitions of the action is:8\n",
      "-----------------\n",
      "The file name is user02_lab.csv middle class_num=7 the number of repetitions of the action is:9\n",
      "The file name is user02_natural.csv middle class_num=7 the number of repetitions of the action is:9\n",
      "The file name is user02_fluorescent.csv middle class_num=7 the number of repetitions of the action is:7\n",
      "The file name is user02_led.csv middle class_num=7 the number of repetitions of the action is:8\n",
      "The file name is user02_fluorescent_led.csv middle class_num=7 the number of repetitions of the action is:7\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "# get the number of natural data cycle prediction values \n",
    "from time_series_scripts import cycle_count\n",
    "\n",
    "pred_count = cycle_count.get_all_count(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file name is a3_b7.csv the number of repetitions of the action is:7\n",
      "The file name is b18.csv the number of repetitions of the action is:18\n",
      "The file name is a.csv the number of repetitions of the action is:1\n",
      "The file name is a17.csv the number of repetitions of the action is:16\n",
      "The file name is b7.csv the number of repetitions of the action is:7\n",
      "The file name is b3_a17_b3.csv the number of repetitions of the action is:22\n",
      "The file name is b13_a3.csv the number of repetitions of the action is:13\n",
      "The file name is b.csv the number of repetitions of the action is:1\n",
      "The file name is b3_a12_b3.csv the number of repetitions of the action is:12\n",
      "The file name is b18_a3.csv the number of repetitions of the action is:18\n",
      "The file name is a3_b18.csv the number of repetitions of the action is:21\n",
      "The file name is a_b7_a.csv the number of repetitions of the action is:6\n",
      "The file name is b7_a3.csv the number of repetitions of the action is:7\n",
      "The file name is a3_b13.csv the number of repetitions of the action is:16\n",
      "The file name is a3.csv the number of repetitions of the action is:2\n",
      "The file name is a12.csv the number of repetitions of the action is:11\n",
      "The file name is b13.csv the number of repetitions of the action is:13\n",
      "The file name is b_a7_b.csv the number of repetitions of the action is:6\n",
      "The file name is a3_b18_a3.csv the number of repetitions of the action is:18\n",
      "The file name is a7.csv the number of repetitions of the action is:6\n",
      "The file name is a3_b13_a3.csv the number of repetitions of the action is:13\n",
      "The file name is b3.csv the number of repetitions of the action is:3\n"
     ]
    }
   ],
   "source": [
    "# obtain artificial synthetic data cycle prediction value \n",
    "pred_count_artificial = cycle_count.get_all_count(files, nature_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'time_series_scripts.cycle_count' has no attribute 'print_artificial_MAE_OBO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcycle_count\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_artificial_MAE_OBO\u001b[49m(files, artificial_real_count, pred_count_artificial, repnet_artificial_pred_count)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'time_series_scripts.cycle_count' has no attribute 'print_artificial_MAE_OBO'"
     ]
    }
   ],
   "source": [
    "cycle_count.print_artificial_MAE_OBO(files, artificial_real_count, pred_count_artificial, repnet_artificial_pred_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "def intermediate_PCA_method(data: pd.DataFrame):\n",
    "    data = data.values \n",
    "    ipca = IncrementalPCA(n_components=1, batch_size=10)\n",
    "    ipca_data = ipca.fit_transform(data)\n",
    "    ipca_data = np.reshape(ipca_data, -1) \n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA \n",
    "def dimensionality_reduction_IPCA(file_name,class_num,nature_flag=True):\n",
    "    df = None \n",
    "    to_file_path = None \n",
    "    os.makedirs(f'../../event_csv/compress_event_manhattan/articicial/smooth_by_ipca/', exist_ok=True) \n",
    "\n",
    "    if nature_flag:\n",
    "        # Data after time and space filtration\n",
    "        df = pd.read_csv(f'../../event_csv/compress_event_manhattan/class{class_num}/{file_name}')\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/smooth_by_ipca/{file_name}'\n",
    "    else:\n",
    "        df = pd.read_csv(f'../../event_csv/compress_event_manhattan/articicial/{file_name}')\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/articicial/smooth_by_ipca/{file_name}'\n",
    "    # PCA main component analysis, as long as the first dimension \n",
    "    data = intermediate_PCA_method(df)\n",
    "    pd.DataFrame(data, columns=['value']).to_csv(\n",
    "        to_file_path, mode='w', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../../event_csv/compress_event_manhattan/class4/smooth_by_ipca'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m file_names:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mdimensionality_reduction_IPCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m, in \u001b[0;36mdimensionality_reduction_IPCA\u001b[0;34m(file_name, class_num, nature_flag)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# PCA main component analysis, as long as the first dimension \u001b[39;00m\n\u001b[1;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m intermediate_PCA_method(df)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyenv/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyenv/lib/python3.11/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyenv/lib/python3.11/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyenv/lib/python3.11/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/anaconda3/envs/pyenv/lib/python3.11/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyenv/lib/python3.11/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../../event_csv/compress_event_manhattan/class4/smooth_by_ipca'"
     ]
    }
   ],
   "source": [
    "file_names = os.listdir(\"../../event_csv/split_data/class2/\")\n",
    "for i in range(2, 8):\n",
    "    if i == 3:\n",
    "        continue \n",
    "    for name in file_names:\n",
    "        dimensionality_reduction_IPCA(name, class_num=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
