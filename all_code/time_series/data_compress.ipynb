{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23733a1d",
   "metadata": {},
   "source": [
    "# Manhattan compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78dd5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhattan distance with two coordinates\n",
    "def compute_distance(x1,y1,x2,y2):\n",
    "    return abs(x1-x2),abs(y1-y2)\n",
    "\n",
    "# By comparing with the next event point, determine whether the current event point is noise\n",
    "def is_noise(row,next_event,delta):\n",
    "    # The next point of the current point is too far away and count == 1, then the current point is considered a noise point\n",
    "    x_dis,y_dis = compute_distance(row[1],row[2],next_event[1],next_event[2])\n",
    "    # The current event point is noise, skipping does not enter\n",
    "    if x_dis > delta or y_dis > delta:\n",
    "        # Noise point\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# Write the aggregation point into the CSV file\n",
    "def write_to_csv(temp_x,temp_y,count,path):\n",
    "    pd.DataFrame(data=[[temp_x/count,temp_y/count]]).to_csv(path,\n",
    "                                                   mode='a',header=False,index=False)\n",
    "# Select the starting point of the cluster\n",
    "def select_start_point(df,delta):\n",
    "    for index,row in df.iterrows():\n",
    "        d1,d2 = compute_distance(row[1],row[2],df['x'][index+1],df['y'][index+1])\n",
    "        if d1 <= delta and d2 < delta:\n",
    "            # Explain that there are other points around the current point, the probability is not the noise point\n",
    "            return index,row      \n",
    "# Manhattan compression\n",
    "def compress_by_Manhattan(file_name,class_num,delta=5,count_margin=100,nature_flag=True):\n",
    "    file_path = None\n",
    "    to_file_path = None\n",
    "    # Natural data path\n",
    "    if nature_flag:\n",
    "        file_path = f'../../event_csv/split_data/class{class_num}/{file_name}'\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/{file_name}'\n",
    "    # Artificial synthesis data path\n",
    "    else:\n",
    "        file_path = f'../../event_csv/split_data/artificial/{file_name}'\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/articicial/{file_name}'  \n",
    "    \n",
    "#     df = pd.read_csv(file_path,skiprows=1)\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Manhattan distance comparison object [The initial point may be noise point]\n",
    "    start,row = select_start_point(df,delta)\n",
    "    # row[0] is the timestamp column\n",
    "    baseline_x = row[1]\n",
    "    baseline_y = row[2]\n",
    "    \n",
    "    # Manhattan distance to be written\n",
    "    temp_x = 0\n",
    "    temp_y = 0\n",
    "    count = 0\n",
    "    pd.DataFrame(data=[['x','y']]).to_csv(to_file_path,mode='w',header=False,index=False)\n",
    "    # Travel every line\n",
    "    for index,row in df.iterrows():\n",
    "        if index < start:\n",
    "            continue\n",
    "        # At the distance from Manhattan, gather at a point, take the average value\n",
    "        x_dis,y_dis = compute_distance(baseline_x,baseline_y,row[1],row[2])\n",
    "        # Focus on up to count_margin a point\n",
    "        if x_dis <= delta and y_dis <= delta and count < count_margin:\n",
    "            # Tanchen at average\n",
    "            count = count + 1\n",
    "            temp_x = temp_x + row[1]\n",
    "            temp_y = temp_y + row[2]\n",
    "        else:\n",
    "            # Come to the last event point location\n",
    "            if index + 1 >= df.shape[0]:\n",
    "                if count > 1:\n",
    "                    write_to_csv(temp_x,temp_y,count,to_file_path)\n",
    "                break\n",
    "            next_event = df.iloc[index+1]\n",
    "            # The next point of the current point is too far away and count == 1, then the current point is considered a noise point\n",
    "            if count == 1 and is_noise(row,next_event,delta):\n",
    "                # The current event point is noise and will be skipped and not entered.\n",
    "                continue\n",
    "            write_to_csv(temp_x,temp_y,count,to_file_path)\n",
    "            baseline_x = row[1]\n",
    "            baseline_y = row[2]\n",
    "            temp_x = row[1]\n",
    "            temp_y = row[2]\n",
    "            count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68d6107",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1237970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionality_reduction_PCA(file_name,class_num,nature_flag=True):\n",
    "    df = None\n",
    "    to_file_path = None\n",
    "    if nature_flag:\n",
    "        # Data after time and space filtration\n",
    "        df = pd.read_csv(f'../../event_csv/compress_event_manhattan/class{class_num}/{file_name}')\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/smooth_by_pca/{file_name}'\n",
    "    else:\n",
    "        df = pd.read_csv(f'../../event_csv/compress_event_manhattan/articicial/{file_name}')\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/articicial/smooth_by_pca/{file_name}'\n",
    "    # PCA main component analysis, as long as the first dimension\n",
    "    data = PCA_method(df)\n",
    "    pd.DataFrame(data,columns=['value']).to_csv(to_file_path,mode='w',header=True,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e41985",
   "metadata": {},
   "source": [
    "# mean compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5cecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_by_mean(file_name,class_num,chunksize=100,nature_flag=True):\n",
    "    file_path = None\n",
    "    to_file_path = None\n",
    "    if nature_flag:\n",
    "        file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/smooth_by_pca/{file_name}'\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/class{class_num}/smooth_by_pca/compress_by_mean/{file_name}'\n",
    "    else:\n",
    "        # Artificial synthesis data path\n",
    "        file_path = f'../../event_csv/compress_event_manhattan/articicial/smooth_by_pca/{file_name}'\n",
    "        to_file_path = f'../../event_csv/compress_event_manhattan/articicial/smooth_by_pca/compress_by_mean/{file_name}'\n",
    "\n",
    "    df = pd.read_csv(file_path,chunksize=chunksize,usecols=['value'])\n",
    "    pd.DataFrame(data=[['value']]).to_csv(to_file_path,mode='w',header=False,index=False)\n",
    "    for chunk in df:\n",
    "        temp = pd.DataFrame([chunk.mean()])\n",
    "        temp.to_csv(to_file_path,index=False,header=False,mode='a')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2362ff7b",
   "metadata": {},
   "source": [
    "# Two -person integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e76773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waveform smooth\n",
    "def distance_mean_meanline(file_name,class_num=-1,delta=5,count=100,mean_count=100,nature_flag=True):\n",
    "    # Manhattan distance compression\n",
    "    compress_by_Manhattan(file_name,class_num,delta=delta,count_margin=count,nature_flag=nature_flag)\n",
    "    # PCA + HP filter\n",
    "    dimensionality_reduction_PCA(file_name,class_num,nature_flag=nature_flag)\n",
    "    # Average compression\n",
    "    compress_by_mean(file_name,class_num,chunksize=mean_count,nature_flag=nature_flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
